{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cópia de gabarito_pln_ciencia_dados.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "doNarAZw9mna"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitor-dias1/Python/blob/master/PLN_ciencia_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de Processamento de Linguagem Natural (PLN)\n",
        "\n",
        "Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais. Neste *notebook* iremos aprender de forma prática algumas técnicas de Técnicas de Processamento de Linguagem Natural (PLN) usadas na área de Ciência de Dados."
      ],
      "metadata": {
        "id": "gFoZCrLxen3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WP1hpI5W78M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Toolkit\n",
        "\n",
        "[NLTK](https://www.nltk.org/) é uma plataforma líder para construir programas Python para trabalhar com dados de linguagem humana. Ele fornece interfaces fáceis de usar para mais de 50 corpora e recursos léxicos, como WordNet, juntamente com um conjunto de bibliotecas de processamento de texto para classificação, tokenização, lematização, marcação, análise e raciocínio semântico, wrappers para bibliotecas NLP de força industrial, e um fórum de discussão ativo."
      ],
      "metadata": {
        "id": "xW_hxlmSaHcf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiV70S9aaDJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2aed609-cf00-413e-dcc9-97cf58baf994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk # Instalação da biblioteca nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk"
      ],
      "metadata": {
        "id": "dphPYQujallU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"all\") # Importa todos os recursos para Processamento de Linguagem Natural com Python"
      ],
      "metadata": {
        "id": "uWCKsipEcpI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-processamento\n",
        "\n",
        "Textos não podem ser tratados diretamente por máquinas, por se tratarem de dados não estruturados. Logo, iremos representá-los em números, para converter nossos dados não estruturados em dados estruturados. A seguir, aprenderemos na prática, algumas técnicas de processamento natural de linguagem para realizarmos essa importante etapa de pré-processamento dos conjuntos de dados textuais."
      ],
      "metadata": {
        "id": "MqBP_ojaaLZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenização\n",
        "\n",
        "Tokenização é o processo de demarcar e possivelmente classificar seções de uma string de caracteres de entrada. Os tokens resultantes são então passados para alguma outra forma de processamento. Resumindo:\n",
        "\n",
        "\n",
        "> **TOKENIZAÇÃO** = Separar palavras de um texto\n",
        "\n"
      ],
      "metadata": {
        "id": "wUtprrQMcJji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'A programação é aprendida escrevendo programas. (Brian Kernighan)'\n",
        "nltk.word_tokenize(texto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMEeOkDjaLkJ",
        "outputId": "0ae8810c-ad47-43e8-fb90-8fb80aa806ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'programação',\n",
              " 'é',\n",
              " 'aprendida',\n",
              " 'escrevendo',\n",
              " 'programas',\n",
              " '.',\n",
              " '(',\n",
              " 'Brian',\n",
              " 'Kernighan',\n",
              " ')']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Tokens sem Números e Pontuações"
      ],
      "metadata": {
        "id": "dMyNIygtsa32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "texto = 'A programação é aprendida escrevendo programas. (Brian Kernighan)'\n",
        "tokenizador = RegexpTokenizer(r'[A-z]\\w*')\n",
        "tokens = tokenizador.tokenize(texto)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGY0aRO3sbHB",
        "outputId": "93a7e7be-a413-4f33-8350-aee52b6790c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'programação', 'aprendida', 'escrevendo', 'programas', 'Brian', 'Kernighan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frequência de Tokens"
      ],
      "metadata": {
        "id": "889J4ztRxWmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'A confirmação do primeiro caso de coronavírus no Brasil, um homem de 61 anos que contraiu a doença em uma viagem à Itália, causou preocupação em todo o País e o Ministério da Saúde precisou colocar em prática medidas de segurança que já vinham sendo estudadas desde janeiro, quando a epidemia surgiu na China. As autoridades sabiam que a chegada do vírus ao Brasil era uma questão de tempo. Outros 20 brasileiros são suspeitos de terem pego o novo vírus, dos quais 12 também passaram pela Itália. Em estado de atenção, o Brasil já pediu à Organização Mundial da Saúde (OMS) que declare a existência de uma pandemia — quando uma doença alastra-se pelo mundo.'\n",
        "tokenizador = RegexpTokenizer(r'[A-z]\\w*')\n",
        "tokens = tokenizador.tokenize(texto)\n",
        "\n",
        "frequencia = nltk.FreqDist(tokens)\n",
        "\n",
        "# Ordena a frequência dos tokens de maneira decrescente\n",
        "frequencia.most_common(20) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDSIGlqGxWB9",
        "outputId": "3fa7d87e-da97-45a1-b9aa-d21e116c0c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 7),\n",
              " ('que', 4),\n",
              " ('a', 4),\n",
              " ('uma', 4),\n",
              " ('o', 4),\n",
              " ('Brasil', 3),\n",
              " ('em', 3),\n",
              " ('do', 2),\n",
              " ('doença', 2),\n",
              " ('Itália', 2),\n",
              " ('da', 2),\n",
              " ('Saúde', 2),\n",
              " ('já', 2),\n",
              " ('quando', 2),\n",
              " ('vírus', 2),\n",
              " ('A', 1),\n",
              " ('confirmação', 1),\n",
              " ('primeiro', 1),\n",
              " ('caso', 1),\n",
              " ('coronavírus', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sensível a Maiúsculas e Minúsculas\n",
        "\n",
        "Perceba que a contagem de tokens considera termos em maiúsculo e minúsculo como sendo tokens diferentes. Caso o objetivo da contagem seja de palavras iguais use as funções `lower()` ou `upper()` para normalizar os tokens.\n",
        "\n"
      ],
      "metadata": {
        "id": "dOQNwLsRzEss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'A confirmação do primeiro caso de coronavírus no Brasil, um homem de 61 anos que contraiu a doença em uma viagem à Itália, causou preocupação em todo o País e o Ministério da Saúde precisou colocar em prática medidas de segurança que já vinham sendo estudadas desde janeiro, quando a epidemia surgiu na China. As autoridades sabiam que a chegada do vírus ao Brasil era uma questão de tempo. Outros 20 brasileiros são suspeitos de terem pego o novo vírus, dos quais 12 também passaram pela Itália. Em estado de atenção, o Brasil já pediu à Organização Mundial da Saúde (OMS) que declare a existência de uma pandemia — quando uma doença alastra-se pelo mundo.'\n",
        "tokenizador = RegexpTokenizer(r'[A-z]\\w*')\n",
        "tokens = tokenizador.tokenize(texto)\n",
        "\n",
        "#print(tokens)\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "  tokens[i] = tokens[i].lower()\n",
        "\n",
        "#print(tokens)\n",
        "\n",
        "frequencia = nltk.FreqDist(tokens)\n",
        "frequencia.most_common(20) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vr1GJlv0IlK",
        "outputId": "1f5945d8-61bd-43a2-f8c6-5ca7832416f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 7),\n",
              " ('a', 5),\n",
              " ('que', 4),\n",
              " ('em', 4),\n",
              " ('uma', 4),\n",
              " ('o', 4),\n",
              " ('brasil', 3),\n",
              " ('do', 2),\n",
              " ('doença', 2),\n",
              " ('itália', 2),\n",
              " ('da', 2),\n",
              " ('saúde', 2),\n",
              " ('já', 2),\n",
              " ('quando', 2),\n",
              " ('vírus', 2),\n",
              " ('confirmação', 1),\n",
              " ('primeiro', 1),\n",
              " ('caso', 1),\n",
              " ('coronavírus', 1),\n",
              " ('no', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Words\n",
        "\n",
        "*Stop Words* são palavras irrelevantes que são removidas antes ou após o processamento de um texto em linguagem natural, por exemplo: artigos, preposições e conjunções.\n"
      ],
      "metadata": {
        "id": "UHY6EBByaLvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "stopwords[:10]\n",
        "#stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fg463bcaL6P",
        "outputId": "41be5d4d-a70b-4f36-b64a-03fc89a8d1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remoção de Stop Words\n",
        "\n",
        "Vamos verificar agoar a frequência de tokens sem a presença de palavras irrelevantes (Stop Words)"
      ],
      "metadata": {
        "id": "3j64Oj88aMWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "texto = 'A confirmação do primeiro caso de coronavírus no Brasil, um homem de 61 anos que contraiu a doença em uma viagem à Itália, causou preocupação em todo o País e o Ministério da Saúde precisou colocar em prática medidas de segurança que já vinham sendo estudadas desde janeiro, quando a epidemia surgiu na China. As autoridades sabiam que a chegada do vírus ao Brasil era uma questão de tempo. Outros 20 brasileiros são suspeitos de terem pego o novo vírus, dos quais 12 também passaram pela Itália. Em estado de atenção, o Brasil já pediu à Organização Mundial da Saúde (OMS) que declare a existência de uma pandemia — quando uma doença alastra-se pelo mundo.'\n",
        "tokenizador = RegexpTokenizer(r'[A-z]\\w*')\n",
        "tokens = tokenizador.tokenize(texto)\n",
        "\n",
        "tokens_sem_stopwords = []\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "\n",
        "  tokens[i] = tokens[i].lower()\n",
        "\n",
        "  if tokens[i] not in stopwords:\n",
        "    tokens_sem_stopwords.append(tokens[i])\n",
        "\n",
        "\n",
        "# print(tokens_sem_stopwords)\n",
        "\n",
        "frequencia = nltk.FreqDist(tokens_sem_stopwords)\n",
        "frequencia.most_common(20) \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eGPzoZ-aMiy",
        "outputId": "f7d07b53-21ae-4aeb-feea-f26aeae0e400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('brasil', 3),\n",
              " ('doença', 2),\n",
              " ('itália', 2),\n",
              " ('saúde', 2),\n",
              " ('vírus', 2),\n",
              " ('confirmação', 1),\n",
              " ('primeiro', 1),\n",
              " ('caso', 1),\n",
              " ('coronavírus', 1),\n",
              " ('homem', 1),\n",
              " ('anos', 1),\n",
              " ('contraiu', 1),\n",
              " ('viagem', 1),\n",
              " ('causou', 1),\n",
              " ('preocupação', 1),\n",
              " ('todo', 1),\n",
              " ('país', 1),\n",
              " ('ministério', 1),\n",
              " ('precisou', 1),\n",
              " ('colocar', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gfQazbJdJnga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UfTDx-dBJnvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flexão Gramatical\n",
        "\n",
        "Na gramática, flexão ou inflexão é a modificação de uma palavra para expressar diferentes categorias gramaticais, como modo, tempo, voz, aspecto, pessoa, número, gênero e caso. Por exemplo, o verbo ESTUDAR pode aparecer em um texto nas seguintes formas: ESTUDANDO, ESTUDIOSO, ESTUDEI. \n",
        "\n",
        "Sendo assim, para obtermos melhores resultados em nossas análises de dados, as flexões de uma palavra devem ser tratadas da mesma maneira. A seguir, aprenderemos as técnicas de *Stemização* e *Lematização*, que podem ser aplicadas durante o processo de análise de dados textuais.\n"
      ],
      "metadata": {
        "id": "jQ795OSY6Ym2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemização\n",
        "\n",
        "Em morfologia linguística e recuperação de informação a stemização (Stemming) é o processo de reduzir palavras flexionadas ou às vezes derivadas ao seu tronco (Stem), base ou raiz, geralmente uma forma da palavra escrita. \n",
        "\n",
        "> STEMIZAÇÃO = Reduzir a palavra ao seu radical\n",
        "\n",
        "O NLTK tem implementado várias variantes de stemmers:\n",
        "\n",
        "* Removedor de Sufixos da Língua Portuguesa (RSLP): \n",
        "  * Porter\n",
        "  * ISRI\n",
        "  * Lancaster\n",
        "  * Snowball\n"
      ],
      "metadata": {
        "id": "doNarAZw9mna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.RSLPStemmer()\n",
        "\n",
        "print(stemmer.stem('cachorrão'))\n",
        "print(stemmer.stem('cachorrinho'))\n",
        "print(stemmer.stem('cachorro'))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(stemmer.stem('estudando'))\n",
        "print(stemmer.stem('estudo'))\n",
        "print(stemmer.stem('estudei'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tcnjhe86Y0T",
        "outputId": "8dd8011f-4a38-4dea-e8a9-c2ccd129fa2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cachorr\n",
            "cachorr\n",
            "cachorr\n",
            "\n",
            "\n",
            "estud\n",
            "estud\n",
            "estud\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lematização\n",
        "\n",
        "Lematização (ou lematização) em linguística é o processo de agrupar as formas flexionadas de uma palavra para que possam ser analisadas como um único item, identificado pelo lema da palavra, ou forma de dicionário.\n",
        "\n",
        "> LEMATIZAÇÃO = Reduzir a palavra à sua forma canônica, levando em conta sua classe gramatical.\n",
        "\n",
        "Embora um lematizador seja mais complexo de implementar ou mais lento comparado ao processo de Stematização; ele, é mais acurado e causará menos ruído nos resultados finais das análises.\n",
        "\n"
      ],
      "metadata": {
        "id": "OQbN39OM6Y-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lematizador = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "# O parâmetro pos indica a etiqueta da parte do discurso. \n",
        "# As opções válidas são n para substantivos, `\"v\"` para verbos, \n",
        "# `\"a\"` para adjetivos, `\"r\"` para advérbios e `\"s\"` para adjetivos satélites.\n",
        "print(lematizador.lemmatize('propõem', pos='v'))\n",
        "print(lematizador.lemmatize('cachorrão', pos='n'))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(lematizador.lemmatize('studying', pos='v'))\n",
        "print(lematizador.lemmatize('studied', pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW0gvNmn6ZIq",
        "outputId": "d82ce304-f3de-47b1-a2d4-4ff922ec281d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "propõem\n",
            "cachorrão\n",
            "\n",
            "\n",
            "study\n",
            "study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceba que o NLTK funciona bem para a língua inglesa, porém, não tem um lematizador bom para a língua Portuguesa. Para fazer a lematização para a língua portuguesa, use a biblioteca [spaCy](https://spacy.io/usage)"
      ],
      "metadata": {
        "id": "57GV-uPlB9Re"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vetorização\n",
        "\n",
        "Nesta etapa as palavras são convertidas em números retornados em vetores para que possam ser processados pelos algoritmos. Aqui usaremos a biblioteca Python de Aprendizagem de Máquina chamada [scikit-learn](https://scikit-learn.org/stable/)"
      ],
      "metadata": {
        "id": "xkK81ngM6ZUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo Saco de Palavras (Bag of Words)\n",
        "\n",
        "O modelo saco-de-palavras é uma representação simplificada utilizada no processamento de linguagem natural e na recuperação de informações. Neste modelo, o texto (uma frase ou documento) é representado como um multiconjunto de suas palavras (o \"saco\"), desconsiderando a estrutura gramatical e até mesmo a ordenação delas, mas mantendo sua multiplicidade.\n",
        "\n",
        "O modelo saco-de-palavras é frequentemente utilizado em métodos de classificação de documentos, onde a frequência de ocorrência de cada palavra é vista como uma característica utilizada para treinar o classificador."
      ],
      "metadata": {
        "id": "e2naN8JHKIjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "textos = ['Eu gosto muito do produto. A qualidade é muito boa.',\n",
        "         'O produto é muito bom',\n",
        "         'O Produto foi entregue quebrado',\n",
        "         'O produto é bom, mas é caro',\n",
        "         'O produto não é bom'\n",
        "]\n",
        "\n",
        "\n",
        "bag_of_words = CountVectorizer()\n",
        "\n",
        "print(bag_of_words.fit_transform(textos).toarray())\n",
        "print('\\n')\n",
        "print('Características:', bag_of_words.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq8Jn7nD6ZfW",
        "outputId": "6fee6f29-eefc-41bd-8cef-22f5f87cfe23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0 1 0 1 0 1 0 2 0 1 1 0]\n",
            " [0 1 0 0 0 0 0 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 1 0 1 0 0 0 0 1 0 1]\n",
            " [0 1 1 0 0 0 0 0 1 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 1 1 0 0]]\n",
            "\n",
            "\n",
            "Características: ['boa' 'bom' 'caro' 'do' 'entregue' 'eu' 'foi' 'gosto' 'mas' 'muito' 'não'\n",
            " 'produto' 'qualidade' 'quebrado']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "texto = 'A confirmação do primeiro caso de coronavírus no Brasil, um homem de 61 anos que contraiu a doença em uma viagem à Itália, causou preocupação em todo o País e o Ministério da Saúde precisou colocar em prática medidas de segurança que já vinham sendo estudadas desde janeiro, quando a epidemia surgiu na China. As autoridades sabiam que a chegada do vírus ao Brasil era uma questão de tempo. Outros 20 brasileiros são suspeitos de terem pego o novo vírus, dos quais 12 também passaram pela Itália. Em estado de atenção, o Brasil já pediu à Organização Mundial da Saúde (OMS) que declare a existência de uma pandemia — quando uma doença alastra-se pelo mundo.'\n",
        "tokenizador = RegexpTokenizer(r'[A-z]\\w*')\n",
        "tokens = tokenizador.tokenize(texto)\n",
        "\n",
        "tokens_sem_stopwords = []\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "\n",
        "  tokens[i] = tokens[i].lower()\n",
        "\n",
        "  if tokens[i] not in stopwords:\n",
        "    tokens_sem_stopwords.append(tokens[i])\n",
        "\n",
        "\n",
        "\n",
        "bag_of_words = CountVectorizer()\n",
        "\n",
        "print(bag_of_words.fit_transform(tokens_sem_stopwords).toarray())\n",
        "print('\\n')\n",
        "print('Características:', bag_of_words.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSbWIl5VPJ-m",
        "outputId": "90dd5025-c46a-4edf-98d6-b0492c08bc98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "\n",
            "Características: ['alastra' 'anos' 'atenção' 'autoridades' 'brasil' 'brasileiros' 'caso'\n",
            " 'causou' 'chegada' 'china' 'colocar' 'confirmação' 'contraiu'\n",
            " 'coronavírus' 'declare' 'desde' 'doença' 'epidemia' 'estado' 'estudadas'\n",
            " 'existência' 'homem' 'itália' 'janeiro' 'medidas' 'ministério' 'mundial'\n",
            " 'mundo' 'novo' 'oms' 'organização' 'outros' 'pandemia' 'passaram' 'país'\n",
            " 'pediu' 'pego' 'precisou' 'preocupação' 'primeiro' 'prática' 'quais'\n",
            " 'questão' 'sabiam' 'saúde' 'segurança' 'sendo' 'surgiu' 'suspeitos'\n",
            " 'tempo' 'terem' 'todo' 'viagem' 'vinham' 'vírus']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *n-gram*\n",
        "\n",
        "Nas áreas de linguística computacional e probabilidade, um n-gram (às vezes também chamado de Q-gram) é uma sequência contígua de n itens de uma determinada amostra de texto ou fala. Os itens podem ser fonemas, sílabas, letras, palavras ou pares de bases de acordo com a aplicação. Os n-grams normalmente são coletados de um texto ou corpus de fala."
      ],
      "metadata": {
        "id": "LXB8XqIf6Zqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "textos = ['Eu gosto muito do produto. A qualidade é muito boa.',\n",
        "         'O produto é muito bom',\n",
        "         'O Produto foi entregue quebrado',\n",
        "         'O produto é bom, mas é caro',\n",
        "         'O produto não é bom'\n",
        "]\n",
        "\n",
        "\n",
        "vetor_contagens = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
        "\n",
        "print(vetor_contagens.fit_transform(textos).toarray())\n",
        "print('\\n')\n",
        "print('Características:', vetor_contagens.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LEcTIrS6Z1a",
        "outputId": "c020e0f0-9e81-4195-bafb-349343b71fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 2 1 0 1 0 0 1 0 0 0 0 1 1 1 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1]\n",
            " [0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0]]\n",
            "\n",
            "\n",
            "Características: ['boa' 'bom' 'bom mas' 'caro' 'do' 'do produto' 'entregue'\n",
            " 'entregue quebrado' 'eu' 'eu gosto' 'foi' 'foi entregue' 'gosto'\n",
            " 'gosto muito' 'mas' 'mas caro' 'muito' 'muito boa' 'muito bom' 'muito do'\n",
            " 'não' 'não bom' 'produto' 'produto bom' 'produto foi' 'produto muito'\n",
            " 'produto não' 'produto qualidade' 'qualidade' 'qualidade muito'\n",
            " 'quebrado']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "texto = 'A confirmação do primeiro caso de coronavírus no Brasil, um homem de 61 anos que contraiu a doença em uma viagem à Itália, causou preocupação em todo o País e o Ministério da Saúde precisou colocar em prática medidas de segurança que já vinham sendo estudadas desde janeiro, quando a epidemia surgiu na China. As autoridades sabiam que a chegada do vírus ao Brasil era uma questão de tempo. Outros 20 brasileiros são suspeitos de terem pego o novo vírus, dos quais 12 também passaram pela Itália. Em estado de atenção, o Brasil já pediu à Organização Mundial da Saúde (OMS) que declare a existência de uma pandemia — quando uma doença alastra-se pelo mundo.'\n",
        "tokenizador = RegexpTokenizer(r'[A-z]\\w*')\n",
        "tokens = tokenizador.tokenize(texto)\n",
        "\n",
        "tokens_sem_stopwords = []\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "\n",
        "  tokens[i] = tokens[i].lower()\n",
        "\n",
        "  if tokens[i] not in stopwords:\n",
        "    tokens_sem_stopwords.append(tokens[i])\n",
        "\n",
        "\n",
        "\n",
        "vetor_contagens = CountVectorizer(analyzer='word', ngram_range=(1, 3))\n",
        "\n",
        "print(vetor_contagens.fit_transform(tokens_sem_stopwords).toarray())\n",
        "print('\\n')\n",
        "print('Características:', vetor_contagens.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_ssIS-wP-CY",
        "outputId": "ea0b6ad2-111f-4ce3-8126-503922ba5462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "\n",
            "Características: ['alastra' 'anos' 'atenção' 'autoridades' 'brasil' 'brasileiros' 'caso'\n",
            " 'causou' 'chegada' 'china' 'colocar' 'confirmação' 'contraiu'\n",
            " 'coronavírus' 'declare' 'desde' 'doença' 'epidemia' 'estado' 'estudadas'\n",
            " 'existência' 'homem' 'itália' 'janeiro' 'medidas' 'ministério' 'mundial'\n",
            " 'mundo' 'novo' 'oms' 'organização' 'outros' 'pandemia' 'passaram' 'país'\n",
            " 'pediu' 'pego' 'precisou' 'preocupação' 'primeiro' 'prática' 'quais'\n",
            " 'questão' 'sabiam' 'saúde' 'segurança' 'sendo' 'surgiu' 'suspeitos'\n",
            " 'tempo' 'terem' 'todo' 'viagem' 'vinham' 'vírus']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tf-Idf\n",
        "\n",
        "O valor tf–idf (frequency–inverse document frequency), que significa frequência do termo–inverso da frequência nos documentos, é uma medida estatística que tem o intuito de indicar a importância de uma palavra de um documento em relação a uma coleção de documentos ou em um corpus linguístico. Ela é frequentemente utilizada como fator de ponderação na recuperação de informações e na mineração de dados."
      ],
      "metadata": {
        "id": "YvwWDIt56aBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "textos = ['Eu gosto muito do produto. A qualidade é muito boa.',\n",
        "         'O produto é muito bom',\n",
        "         'O Produto foi entregue quebrado',\n",
        "         'O produto é bom, mas é caro',\n",
        "         'O produto não é bom'\n",
        "]\n",
        "\n",
        "vetor_tf_idf = TfidfVectorizer(use_idf=True,\n",
        "                               smooth_idf=False,\n",
        "                               ngram_range=(1, 1))\n",
        "\n",
        "tfs = vetor_tf_idf.fit_transform(textos)\n",
        "features_names = vetor_tf_idf.get_feature_names_out()\n",
        "\n",
        "print(tfs.todense())\n",
        "print('\\n')\n",
        "print('Características:', features_names)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(tfs.todense(), index=textos, columns=features_names)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "HvWLqSdq6aNF",
        "outputId": "2a54ccd3-a967-4747-8c69-2230ac3c5513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.3700139  0.         0.         0.3700139  0.         0.3700139\n",
            "  0.         0.3700139  0.         0.54345359 0.         0.14179832\n",
            "  0.3700139  0.        ]\n",
            " [0.         0.5728925  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.72664149 0.         0.37919167\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.56371713 0.\n",
            "  0.56371713 0.         0.         0.         0.         0.2160301\n",
            "  0.         0.56371713]\n",
            " [0.         0.36750147 0.63473393 0.         0.         0.\n",
            "  0.         0.         0.63473393 0.         0.         0.24324546\n",
            "  0.         0.        ]\n",
            " [0.         0.47558799 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.82141666 0.31478682\n",
            "  0.         0.        ]]\n",
            "\n",
            "\n",
            "Características: ['boa' 'bom' 'caro' 'do' 'entregue' 'eu' 'foi' 'gosto' 'mas' 'muito' 'não'\n",
            " 'produto' 'qualidade' 'quebrado']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                         boa       bom  \\\n",
              "Eu gosto muito do produto. A qualidade é muito ...  0.370014  0.000000   \n",
              "O produto é muito bom                               0.000000  0.572892   \n",
              "O Produto foi entregue quebrado                     0.000000  0.000000   \n",
              "O produto é bom, mas é caro                         0.000000  0.367501   \n",
              "O produto não é bom                                 0.000000  0.475588   \n",
              "\n",
              "                                                        caro        do  \\\n",
              "Eu gosto muito do produto. A qualidade é muito ...  0.000000  0.370014   \n",
              "O produto é muito bom                               0.000000  0.000000   \n",
              "O Produto foi entregue quebrado                     0.000000  0.000000   \n",
              "O produto é bom, mas é caro                         0.634734  0.000000   \n",
              "O produto não é bom                                 0.000000  0.000000   \n",
              "\n",
              "                                                    entregue        eu  \\\n",
              "Eu gosto muito do produto. A qualidade é muito ...  0.000000  0.370014   \n",
              "O produto é muito bom                               0.000000  0.000000   \n",
              "O Produto foi entregue quebrado                     0.563717  0.000000   \n",
              "O produto é bom, mas é caro                         0.000000  0.000000   \n",
              "O produto não é bom                                 0.000000  0.000000   \n",
              "\n",
              "                                                         foi     gosto  \\\n",
              "Eu gosto muito do produto. A qualidade é muito ...  0.000000  0.370014   \n",
              "O produto é muito bom                               0.000000  0.000000   \n",
              "O Produto foi entregue quebrado                     0.563717  0.000000   \n",
              "O produto é bom, mas é caro                         0.000000  0.000000   \n",
              "O produto não é bom                                 0.000000  0.000000   \n",
              "\n",
              "                                                         mas     muito  \\\n",
              "Eu gosto muito do produto. A qualidade é muito ...  0.000000  0.543454   \n",
              "O produto é muito bom                               0.000000  0.726641   \n",
              "O Produto foi entregue quebrado                     0.000000  0.000000   \n",
              "O produto é bom, mas é caro                         0.634734  0.000000   \n",
              "O produto não é bom                                 0.000000  0.000000   \n",
              "\n",
              "                                                         não   produto  \\\n",
              "Eu gosto muito do produto. A qualidade é muito ...  0.000000  0.141798   \n",
              "O produto é muito bom                               0.000000  0.379192   \n",
              "O Produto foi entregue quebrado                     0.000000  0.216030   \n",
              "O produto é bom, mas é caro                         0.000000  0.243245   \n",
              "O produto não é bom                                 0.821417  0.314787   \n",
              "\n",
              "                                                    qualidade  quebrado  \n",
              "Eu gosto muito do produto. A qualidade é muito ...   0.370014  0.000000  \n",
              "O produto é muito bom                                0.000000  0.000000  \n",
              "O Produto foi entregue quebrado                      0.000000  0.563717  \n",
              "O produto é bom, mas é caro                          0.000000  0.000000  \n",
              "O produto não é bom                                  0.000000  0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f964a02f-6ad2-4855-813f-825a91e0914b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>boa</th>\n",
              "      <th>bom</th>\n",
              "      <th>caro</th>\n",
              "      <th>do</th>\n",
              "      <th>entregue</th>\n",
              "      <th>eu</th>\n",
              "      <th>foi</th>\n",
              "      <th>gosto</th>\n",
              "      <th>mas</th>\n",
              "      <th>muito</th>\n",
              "      <th>não</th>\n",
              "      <th>produto</th>\n",
              "      <th>qualidade</th>\n",
              "      <th>quebrado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Eu gosto muito do produto. A qualidade é muito boa.</th>\n",
              "      <td>0.370014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.370014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.370014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.370014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.543454</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141798</td>\n",
              "      <td>0.370014</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O produto é muito bom</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.726641</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.379192</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O Produto foi entregue quebrado</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.563717</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.563717</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.216030</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.563717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O produto é bom, mas é caro</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.367501</td>\n",
              "      <td>0.634734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.634734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.243245</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O produto não é bom</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.475588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.821417</td>\n",
              "      <td>0.314787</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f964a02f-6ad2-4855-813f-825a91e0914b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f964a02f-6ad2-4855-813f-825a91e0914b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f964a02f-6ad2-4855-813f-825a91e0914b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entregue = 0.563717\n",
        "Quebrado = 0.563717\n",
        "Produto = 0.314787"
      ],
      "metadata": {
        "id": "-MxYfsJ_a-uF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JOSIFBO26aW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algortimos de Aprendizado de Máquina\n",
        "\n",
        "Após a conclusão das etapas de processamento, os dados estão prontos para serem passados ​​para um algoritmo de Aprendizado de Máquina para ajuste e previsão. Este é um processo iterativo no qual um algoritmo adequado é escolhido e o ajuste dos parâmetros são feitos."
      ],
      "metadata": {
        "id": "b05UQI_dJqS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo: Notícia da ISTOÉ • Coronavírus Chega ao Brasil"
      ],
      "metadata": {
        "id": "YQqqU17KszEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/data/coronavirus_istoe.txt\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dados = pd.read_csv('/content/drive/MyDrive/data/coronavirus_istoe.txt', sep=\"\\n\", header=None)\n",
        "\n",
        "noticia_covid = []\n",
        "\n",
        "\n",
        "for i in range(len(dados.values)):\n",
        "  noticia_covid.append(dados.values[i][0])\n",
        "\n",
        "noticia_covid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2GTlFImrJNT",
        "outputId": "6157d555-00e7-41b3-bc90-f6b8225bcb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Coronavírus chega ao Brasil',\n",
              " 'Anna França, 28/02/20 - 09h30',\n",
              " 'Com a primeira vítima confirmada e uma série de novos suspeitos de contaminação pela epidemia, o Brasil começa a enfrentar seu grande teste sanitário e de esclarecimento à população. O drama é que essa praga se alastra inclusive pelos mercados, criando pânico e comprometendo também os planos de crescimento do Brasil',\n",
              " 'A confirmação do primeiro caso de coronavírus no Brasil, um homem de 61 anos que contraiu a doença em uma viagem à Itália, causou preocupação em todo o País e o Ministério da Saúde precisou colocar em prática medidas de segurança que já vinham sendo estudadas desde janeiro, quando a epidemia surgiu na China. As autoridades sabiam que a chegada do vírus ao Brasil era uma questão de tempo. Outros 20 brasileiros são suspeitos de terem pego o novo vírus, dos quais 12 também passaram pela Itália. Em estado de atenção, o Brasil já pediu à Organização Mundial da Saúde (OMS) que declare a existência de uma pandemia — quando uma doença alastra-se pelo mundo.',\n",
              " 'O brasileiro infectado pelo novo coronavírus mora em São Paulo e viajou para o norte da Itália entre 9 e 21 de fevereiro. Para voltar ao Brasil, o idoso embarcou no Aeroporto Charles de Gaulle, em Paris, no dia 20, pela Air France, e pousou no Aeroporto de Cumbica, em Guarulhos, na sexta-feira 21. Durante a viagem, ele esteve, a trabalho, nas cidades de Verona e Turim, uma das regiões mais afetadas pela epidemia na Europa. Na chegada a São Paulo, ele se reuniu com cerca de 30 parentes na casa de um dos filhos no domingo 23 para uma confraternização no Carnaval. Uma neta do empresário chegou a apresentar sintomas da doença, mas as autoridades sanitárias apenas acompanham a evolução do caso e não confirmam se ela está contaminada pelo Covid-19, como foi denominado o novo vírus. No domingo à noite ele começou a sentir os sintomas do vírus, como febre, tosse seca, dor de garganta e coriza. Na segunda-feira, o homem procurou o Hospital Albert Einstein. Os médicos fizeram o teste, confirmando a moléstia. Na terça-feira 25, o Instituto Adolf Lutz fez a contraprova e não restou mais dúvidas: era o primeiro brasileiro a pegar a doença que abala o planeta. Entre os parentes, dois adultos e uma criança são de Vinhedo, na Grande São Paulo.',\n",
              " 'Agora, o paciente está confinado em seu apartamento, onde deverá ficar em quarentena por 14 dias. Ele está acompanhado apenas pela mulher, mas em ambientes separados. Ela não apresentou sintomas até agora. “O quadro do homem infectado está evoluindo muito bem”, disse Alberto Kanamura, secretário-executivo da Secretaria Estadual da Saúde. O empresário está sendo orientado a não compartilhar talheres com os demais membros da família e de ter as roupas lavadas e o lixo descartado separadamente. O quadro é leve e não inspira maiores cuidados, mas se houver complicações ele pode ser hospitalizado.',\n",
              " 'Todos os seus familiares também estão sendo monitorados pela vigilância sanitária, bem como 16 passageiros que voltaram com ele no avião e que estiveram nas fileiras à frente, ao lado e atrás dele. Algumas dessas pessoas já foram localizadas e procuraram médicos, mas nenhuma delas apresenta sintomas do coronavírus. O motorista de táxi que o levou do Aeroporto de Cumbica até sua residência já foi contatado, mas também não apresenta sinais da infecção. Segundo o Ministério da Saúde, cada infectado, em média, transmite a doença para outras três pessoas. Os exames de detecção da doença são feitos a partir da coleta de secreções da boca e nariz. Em caso de confirmação da presença do vírus, a contraprova é feita por quatro grandes laboratórios de referência instalados nas principais regiões do País.',\n",
              " 'Dólar dispara',\n",
              " 'A notícia da chegada do vírus ao Brasil acabou provocando pânico. As pessoas correram para as farmácias em busca de máscaras cirúrgicas e álcool gel, esgotando os produtos nas gôndolas. No mercado financeiro, a reação foi imediata. A bolsa despencou 7% só na última quarta-feira, um dia depois do anúncio da entrada do Covid-19 ao País. O dólar voltou a disparar, chegando a R$ 4,50 na quinta-feira 27, atingindo o maior valor nominal de fechamento já registrado. Na indústria, a dificuldade para conseguir peças vindas da China começa a paralisar linhas de produção. O vírus ameaça inclusive as perspectivas de crescimento da economia brasileira. Ao invés de um aumento de 2,5% do PIB, fala-se agora numa alta de no máximo 2%.',\n",
              " 'Fonte: https://istoe.com.br/coronavirus-chega-ao-brasil/']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenização"
      ],
      "metadata": {
        "id": "9diTcInCueOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizador = RegexpTokenizer(r'[A-z]\\w*')\n",
        "tokens_noticia_covid = []\n",
        "\n",
        "for i in range(len(noticia_covid)):\n",
        "  tokens_noticia_covid.append(tokenizador.tokenize(noticia_covid[i]))\n",
        " \n",
        "tokens_noticia_covid"
      ],
      "metadata": {
        "id": "9Lioc9Oiud6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8779fe22-ccdc-45df-c905-af2d00e7940d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Coronavírus', 'chega', 'ao', 'Brasil'],\n",
              " ['Anna', 'França', 'h30'],\n",
              " ['Com',\n",
              "  'a',\n",
              "  'primeira',\n",
              "  'vítima',\n",
              "  'confirmada',\n",
              "  'e',\n",
              "  'uma',\n",
              "  'série',\n",
              "  'de',\n",
              "  'novos',\n",
              "  'suspeitos',\n",
              "  'de',\n",
              "  'contaminação',\n",
              "  'pela',\n",
              "  'epidemia',\n",
              "  'o',\n",
              "  'Brasil',\n",
              "  'começa',\n",
              "  'a',\n",
              "  'enfrentar',\n",
              "  'seu',\n",
              "  'grande',\n",
              "  'teste',\n",
              "  'sanitário',\n",
              "  'e',\n",
              "  'de',\n",
              "  'esclarecimento',\n",
              "  'população',\n",
              "  'O',\n",
              "  'drama',\n",
              "  'que',\n",
              "  'essa',\n",
              "  'praga',\n",
              "  'se',\n",
              "  'alastra',\n",
              "  'inclusive',\n",
              "  'pelos',\n",
              "  'mercados',\n",
              "  'criando',\n",
              "  'pânico',\n",
              "  'e',\n",
              "  'comprometendo',\n",
              "  'também',\n",
              "  'os',\n",
              "  'planos',\n",
              "  'de',\n",
              "  'crescimento',\n",
              "  'do',\n",
              "  'Brasil'],\n",
              " ['A',\n",
              "  'confirmação',\n",
              "  'do',\n",
              "  'primeiro',\n",
              "  'caso',\n",
              "  'de',\n",
              "  'coronavírus',\n",
              "  'no',\n",
              "  'Brasil',\n",
              "  'um',\n",
              "  'homem',\n",
              "  'de',\n",
              "  'anos',\n",
              "  'que',\n",
              "  'contraiu',\n",
              "  'a',\n",
              "  'doença',\n",
              "  'em',\n",
              "  'uma',\n",
              "  'viagem',\n",
              "  'Itália',\n",
              "  'causou',\n",
              "  'preocupação',\n",
              "  'em',\n",
              "  'todo',\n",
              "  'o',\n",
              "  'País',\n",
              "  'e',\n",
              "  'o',\n",
              "  'Ministério',\n",
              "  'da',\n",
              "  'Saúde',\n",
              "  'precisou',\n",
              "  'colocar',\n",
              "  'em',\n",
              "  'prática',\n",
              "  'medidas',\n",
              "  'de',\n",
              "  'segurança',\n",
              "  'que',\n",
              "  'já',\n",
              "  'vinham',\n",
              "  'sendo',\n",
              "  'estudadas',\n",
              "  'desde',\n",
              "  'janeiro',\n",
              "  'quando',\n",
              "  'a',\n",
              "  'epidemia',\n",
              "  'surgiu',\n",
              "  'na',\n",
              "  'China',\n",
              "  'As',\n",
              "  'autoridades',\n",
              "  'sabiam',\n",
              "  'que',\n",
              "  'a',\n",
              "  'chegada',\n",
              "  'do',\n",
              "  'vírus',\n",
              "  'ao',\n",
              "  'Brasil',\n",
              "  'era',\n",
              "  'uma',\n",
              "  'questão',\n",
              "  'de',\n",
              "  'tempo',\n",
              "  'Outros',\n",
              "  'brasileiros',\n",
              "  'são',\n",
              "  'suspeitos',\n",
              "  'de',\n",
              "  'terem',\n",
              "  'pego',\n",
              "  'o',\n",
              "  'novo',\n",
              "  'vírus',\n",
              "  'dos',\n",
              "  'quais',\n",
              "  'também',\n",
              "  'passaram',\n",
              "  'pela',\n",
              "  'Itália',\n",
              "  'Em',\n",
              "  'estado',\n",
              "  'de',\n",
              "  'atenção',\n",
              "  'o',\n",
              "  'Brasil',\n",
              "  'já',\n",
              "  'pediu',\n",
              "  'Organização',\n",
              "  'Mundial',\n",
              "  'da',\n",
              "  'Saúde',\n",
              "  'OMS',\n",
              "  'que',\n",
              "  'declare',\n",
              "  'a',\n",
              "  'existência',\n",
              "  'de',\n",
              "  'uma',\n",
              "  'pandemia',\n",
              "  'quando',\n",
              "  'uma',\n",
              "  'doença',\n",
              "  'alastra',\n",
              "  'se',\n",
              "  'pelo',\n",
              "  'mundo'],\n",
              " ['O',\n",
              "  'brasileiro',\n",
              "  'infectado',\n",
              "  'pelo',\n",
              "  'novo',\n",
              "  'coronavírus',\n",
              "  'mora',\n",
              "  'em',\n",
              "  'São',\n",
              "  'Paulo',\n",
              "  'e',\n",
              "  'viajou',\n",
              "  'para',\n",
              "  'o',\n",
              "  'norte',\n",
              "  'da',\n",
              "  'Itália',\n",
              "  'entre',\n",
              "  'e',\n",
              "  'de',\n",
              "  'fevereiro',\n",
              "  'Para',\n",
              "  'voltar',\n",
              "  'ao',\n",
              "  'Brasil',\n",
              "  'o',\n",
              "  'idoso',\n",
              "  'embarcou',\n",
              "  'no',\n",
              "  'Aeroporto',\n",
              "  'Charles',\n",
              "  'de',\n",
              "  'Gaulle',\n",
              "  'em',\n",
              "  'Paris',\n",
              "  'no',\n",
              "  'dia',\n",
              "  'pela',\n",
              "  'Air',\n",
              "  'France',\n",
              "  'e',\n",
              "  'pousou',\n",
              "  'no',\n",
              "  'Aeroporto',\n",
              "  'de',\n",
              "  'Cumbica',\n",
              "  'em',\n",
              "  'Guarulhos',\n",
              "  'na',\n",
              "  'sexta',\n",
              "  'feira',\n",
              "  'Durante',\n",
              "  'a',\n",
              "  'viagem',\n",
              "  'ele',\n",
              "  'esteve',\n",
              "  'a',\n",
              "  'trabalho',\n",
              "  'nas',\n",
              "  'cidades',\n",
              "  'de',\n",
              "  'Verona',\n",
              "  'e',\n",
              "  'Turim',\n",
              "  'uma',\n",
              "  'das',\n",
              "  'regiões',\n",
              "  'mais',\n",
              "  'afetadas',\n",
              "  'pela',\n",
              "  'epidemia',\n",
              "  'na',\n",
              "  'Europa',\n",
              "  'Na',\n",
              "  'chegada',\n",
              "  'a',\n",
              "  'São',\n",
              "  'Paulo',\n",
              "  'ele',\n",
              "  'se',\n",
              "  'reuniu',\n",
              "  'com',\n",
              "  'cerca',\n",
              "  'de',\n",
              "  'parentes',\n",
              "  'na',\n",
              "  'casa',\n",
              "  'de',\n",
              "  'um',\n",
              "  'dos',\n",
              "  'filhos',\n",
              "  'no',\n",
              "  'domingo',\n",
              "  'para',\n",
              "  'uma',\n",
              "  'confraternização',\n",
              "  'no',\n",
              "  'Carnaval',\n",
              "  'Uma',\n",
              "  'neta',\n",
              "  'do',\n",
              "  'empresário',\n",
              "  'chegou',\n",
              "  'a',\n",
              "  'apresentar',\n",
              "  'sintomas',\n",
              "  'da',\n",
              "  'doença',\n",
              "  'mas',\n",
              "  'as',\n",
              "  'autoridades',\n",
              "  'sanitárias',\n",
              "  'apenas',\n",
              "  'acompanham',\n",
              "  'a',\n",
              "  'evolução',\n",
              "  'do',\n",
              "  'caso',\n",
              "  'e',\n",
              "  'não',\n",
              "  'confirmam',\n",
              "  'se',\n",
              "  'ela',\n",
              "  'está',\n",
              "  'contaminada',\n",
              "  'pelo',\n",
              "  'Covid',\n",
              "  'como',\n",
              "  'foi',\n",
              "  'denominado',\n",
              "  'o',\n",
              "  'novo',\n",
              "  'vírus',\n",
              "  'No',\n",
              "  'domingo',\n",
              "  'noite',\n",
              "  'ele',\n",
              "  'começou',\n",
              "  'a',\n",
              "  'sentir',\n",
              "  'os',\n",
              "  'sintomas',\n",
              "  'do',\n",
              "  'vírus',\n",
              "  'como',\n",
              "  'febre',\n",
              "  'tosse',\n",
              "  'seca',\n",
              "  'dor',\n",
              "  'de',\n",
              "  'garganta',\n",
              "  'e',\n",
              "  'coriza',\n",
              "  'Na',\n",
              "  'segunda',\n",
              "  'feira',\n",
              "  'o',\n",
              "  'homem',\n",
              "  'procurou',\n",
              "  'o',\n",
              "  'Hospital',\n",
              "  'Albert',\n",
              "  'Einstein',\n",
              "  'Os',\n",
              "  'médicos',\n",
              "  'fizeram',\n",
              "  'o',\n",
              "  'teste',\n",
              "  'confirmando',\n",
              "  'a',\n",
              "  'moléstia',\n",
              "  'Na',\n",
              "  'terça',\n",
              "  'feira',\n",
              "  'o',\n",
              "  'Instituto',\n",
              "  'Adolf',\n",
              "  'Lutz',\n",
              "  'fez',\n",
              "  'a',\n",
              "  'contraprova',\n",
              "  'e',\n",
              "  'não',\n",
              "  'restou',\n",
              "  'mais',\n",
              "  'dúvidas',\n",
              "  'era',\n",
              "  'o',\n",
              "  'primeiro',\n",
              "  'brasileiro',\n",
              "  'a',\n",
              "  'pegar',\n",
              "  'a',\n",
              "  'doença',\n",
              "  'que',\n",
              "  'abala',\n",
              "  'o',\n",
              "  'planeta',\n",
              "  'Entre',\n",
              "  'os',\n",
              "  'parentes',\n",
              "  'dois',\n",
              "  'adultos',\n",
              "  'e',\n",
              "  'uma',\n",
              "  'criança',\n",
              "  'são',\n",
              "  'de',\n",
              "  'Vinhedo',\n",
              "  'na',\n",
              "  'Grande',\n",
              "  'São',\n",
              "  'Paulo'],\n",
              " ['Agora',\n",
              "  'o',\n",
              "  'paciente',\n",
              "  'está',\n",
              "  'confinado',\n",
              "  'em',\n",
              "  'seu',\n",
              "  'apartamento',\n",
              "  'onde',\n",
              "  'deverá',\n",
              "  'ficar',\n",
              "  'em',\n",
              "  'quarentena',\n",
              "  'por',\n",
              "  'dias',\n",
              "  'Ele',\n",
              "  'está',\n",
              "  'acompanhado',\n",
              "  'apenas',\n",
              "  'pela',\n",
              "  'mulher',\n",
              "  'mas',\n",
              "  'em',\n",
              "  'ambientes',\n",
              "  'separados',\n",
              "  'Ela',\n",
              "  'não',\n",
              "  'apresentou',\n",
              "  'sintomas',\n",
              "  'até',\n",
              "  'agora',\n",
              "  'O',\n",
              "  'quadro',\n",
              "  'do',\n",
              "  'homem',\n",
              "  'infectado',\n",
              "  'está',\n",
              "  'evoluindo',\n",
              "  'muito',\n",
              "  'bem',\n",
              "  'disse',\n",
              "  'Alberto',\n",
              "  'Kanamura',\n",
              "  'secretário',\n",
              "  'executivo',\n",
              "  'da',\n",
              "  'Secretaria',\n",
              "  'Estadual',\n",
              "  'da',\n",
              "  'Saúde',\n",
              "  'O',\n",
              "  'empresário',\n",
              "  'está',\n",
              "  'sendo',\n",
              "  'orientado',\n",
              "  'a',\n",
              "  'não',\n",
              "  'compartilhar',\n",
              "  'talheres',\n",
              "  'com',\n",
              "  'os',\n",
              "  'demais',\n",
              "  'membros',\n",
              "  'da',\n",
              "  'família',\n",
              "  'e',\n",
              "  'de',\n",
              "  'ter',\n",
              "  'as',\n",
              "  'roupas',\n",
              "  'lavadas',\n",
              "  'e',\n",
              "  'o',\n",
              "  'lixo',\n",
              "  'descartado',\n",
              "  'separadamente',\n",
              "  'O',\n",
              "  'quadro',\n",
              "  'leve',\n",
              "  'e',\n",
              "  'não',\n",
              "  'inspira',\n",
              "  'maiores',\n",
              "  'cuidados',\n",
              "  'mas',\n",
              "  'se',\n",
              "  'houver',\n",
              "  'complicações',\n",
              "  'ele',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'hospitalizado'],\n",
              " ['Todos',\n",
              "  'os',\n",
              "  'seus',\n",
              "  'familiares',\n",
              "  'também',\n",
              "  'estão',\n",
              "  'sendo',\n",
              "  'monitorados',\n",
              "  'pela',\n",
              "  'vigilância',\n",
              "  'sanitária',\n",
              "  'bem',\n",
              "  'como',\n",
              "  'passageiros',\n",
              "  'que',\n",
              "  'voltaram',\n",
              "  'com',\n",
              "  'ele',\n",
              "  'no',\n",
              "  'avião',\n",
              "  'e',\n",
              "  'que',\n",
              "  'estiveram',\n",
              "  'nas',\n",
              "  'fileiras',\n",
              "  'frente',\n",
              "  'ao',\n",
              "  'lado',\n",
              "  'e',\n",
              "  'atrás',\n",
              "  'dele',\n",
              "  'Algumas',\n",
              "  'dessas',\n",
              "  'pessoas',\n",
              "  'já',\n",
              "  'foram',\n",
              "  'localizadas',\n",
              "  'e',\n",
              "  'procuraram',\n",
              "  'médicos',\n",
              "  'mas',\n",
              "  'nenhuma',\n",
              "  'delas',\n",
              "  'apresenta',\n",
              "  'sintomas',\n",
              "  'do',\n",
              "  'coronavírus',\n",
              "  'O',\n",
              "  'motorista',\n",
              "  'de',\n",
              "  'táxi',\n",
              "  'que',\n",
              "  'o',\n",
              "  'levou',\n",
              "  'do',\n",
              "  'Aeroporto',\n",
              "  'de',\n",
              "  'Cumbica',\n",
              "  'até',\n",
              "  'sua',\n",
              "  'residência',\n",
              "  'já',\n",
              "  'foi',\n",
              "  'contatado',\n",
              "  'mas',\n",
              "  'também',\n",
              "  'não',\n",
              "  'apresenta',\n",
              "  'sinais',\n",
              "  'da',\n",
              "  'infecção',\n",
              "  'Segundo',\n",
              "  'o',\n",
              "  'Ministério',\n",
              "  'da',\n",
              "  'Saúde',\n",
              "  'cada',\n",
              "  'infectado',\n",
              "  'em',\n",
              "  'média',\n",
              "  'transmite',\n",
              "  'a',\n",
              "  'doença',\n",
              "  'para',\n",
              "  'outras',\n",
              "  'três',\n",
              "  'pessoas',\n",
              "  'Os',\n",
              "  'exames',\n",
              "  'de',\n",
              "  'detecção',\n",
              "  'da',\n",
              "  'doença',\n",
              "  'são',\n",
              "  'feitos',\n",
              "  'a',\n",
              "  'partir',\n",
              "  'da',\n",
              "  'coleta',\n",
              "  'de',\n",
              "  'secreções',\n",
              "  'da',\n",
              "  'boca',\n",
              "  'e',\n",
              "  'nariz',\n",
              "  'Em',\n",
              "  'caso',\n",
              "  'de',\n",
              "  'confirmação',\n",
              "  'da',\n",
              "  'presença',\n",
              "  'do',\n",
              "  'vírus',\n",
              "  'a',\n",
              "  'contraprova',\n",
              "  'feita',\n",
              "  'por',\n",
              "  'quatro',\n",
              "  'grandes',\n",
              "  'laboratórios',\n",
              "  'de',\n",
              "  'referência',\n",
              "  'instalados',\n",
              "  'nas',\n",
              "  'principais',\n",
              "  'regiões',\n",
              "  'do',\n",
              "  'País'],\n",
              " ['Dólar', 'dispara'],\n",
              " ['A',\n",
              "  'notícia',\n",
              "  'da',\n",
              "  'chegada',\n",
              "  'do',\n",
              "  'vírus',\n",
              "  'ao',\n",
              "  'Brasil',\n",
              "  'acabou',\n",
              "  'provocando',\n",
              "  'pânico',\n",
              "  'As',\n",
              "  'pessoas',\n",
              "  'correram',\n",
              "  'para',\n",
              "  'as',\n",
              "  'farmácias',\n",
              "  'em',\n",
              "  'busca',\n",
              "  'de',\n",
              "  'máscaras',\n",
              "  'cirúrgicas',\n",
              "  'e',\n",
              "  'lcool',\n",
              "  'gel',\n",
              "  'esgotando',\n",
              "  'os',\n",
              "  'produtos',\n",
              "  'nas',\n",
              "  'gôndolas',\n",
              "  'No',\n",
              "  'mercado',\n",
              "  'financeiro',\n",
              "  'a',\n",
              "  'reação',\n",
              "  'foi',\n",
              "  'imediata',\n",
              "  'A',\n",
              "  'bolsa',\n",
              "  'despencou',\n",
              "  'só',\n",
              "  'na',\n",
              "  'ltima',\n",
              "  'quarta',\n",
              "  'feira',\n",
              "  'um',\n",
              "  'dia',\n",
              "  'depois',\n",
              "  'do',\n",
              "  'anúncio',\n",
              "  'da',\n",
              "  'entrada',\n",
              "  'do',\n",
              "  'Covid',\n",
              "  'ao',\n",
              "  'País',\n",
              "  'O',\n",
              "  'dólar',\n",
              "  'voltou',\n",
              "  'a',\n",
              "  'disparar',\n",
              "  'chegando',\n",
              "  'a',\n",
              "  'R',\n",
              "  'na',\n",
              "  'quinta',\n",
              "  'feira',\n",
              "  'atingindo',\n",
              "  'o',\n",
              "  'maior',\n",
              "  'valor',\n",
              "  'nominal',\n",
              "  'de',\n",
              "  'fechamento',\n",
              "  'já',\n",
              "  'registrado',\n",
              "  'Na',\n",
              "  'indústria',\n",
              "  'a',\n",
              "  'dificuldade',\n",
              "  'para',\n",
              "  'conseguir',\n",
              "  'peças',\n",
              "  'vindas',\n",
              "  'da',\n",
              "  'China',\n",
              "  'começa',\n",
              "  'a',\n",
              "  'paralisar',\n",
              "  'linhas',\n",
              "  'de',\n",
              "  'produção',\n",
              "  'O',\n",
              "  'vírus',\n",
              "  'ameaça',\n",
              "  'inclusive',\n",
              "  'as',\n",
              "  'perspectivas',\n",
              "  'de',\n",
              "  'crescimento',\n",
              "  'da',\n",
              "  'economia',\n",
              "  'brasileira',\n",
              "  'Ao',\n",
              "  'invés',\n",
              "  'de',\n",
              "  'um',\n",
              "  'aumento',\n",
              "  'de',\n",
              "  'do',\n",
              "  'PIB',\n",
              "  'fala',\n",
              "  'se',\n",
              "  'agora',\n",
              "  'numa',\n",
              "  'alta',\n",
              "  'de',\n",
              "  'no',\n",
              "  'máximo'],\n",
              " ['Fonte',\n",
              "  'https',\n",
              "  'istoe',\n",
              "  'com',\n",
              "  'br',\n",
              "  'coronavirus',\n",
              "  'chega',\n",
              "  'ao',\n",
              "  'brasil']]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remoção de Stop Words"
      ],
      "metadata": {
        "id": "Wfx5h05St20F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "\n",
        "tokens_sem_stopwords = []\n",
        "\n",
        "print(tokens_noticia_covid)\n",
        "\n",
        "for i in range(len(tokens_noticia_covid)):\n",
        "\n",
        "  for j in range(len(tokens_noticia_covid[i])):\n",
        "    tokens_noticia_covid[i][j] = tokens_noticia_covid[i][j].lower()\n",
        "\n",
        "    if tokens_noticia_covid[i][j] not in stopwords:\n",
        "       tokens_sem_stopwords.append(tokens_noticia_covid[i][j])\n",
        "  \n",
        "\n",
        "print(tokens_noticia_covid)\n",
        "print(tokens_sem_stopwords)\n",
        "\n",
        "#frequencia = nltk.FreqDist(tokens_sem_stopwords)\n",
        "#frequencia.most_common()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvFM41CTt61j",
        "outputId": "917750b8-3727-4226-ab6c-9b12749ff807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Coronavírus', 'chega', 'ao', 'Brasil'], ['Anna', 'França', 'h30'], ['Com', 'a', 'primeira', 'vítima', 'confirmada', 'e', 'uma', 'série', 'de', 'novos', 'suspeitos', 'de', 'contaminação', 'pela', 'epidemia', 'o', 'Brasil', 'começa', 'a', 'enfrentar', 'seu', 'grande', 'teste', 'sanitário', 'e', 'de', 'esclarecimento', 'população', 'O', 'drama', 'que', 'essa', 'praga', 'se', 'alastra', 'inclusive', 'pelos', 'mercados', 'criando', 'pânico', 'e', 'comprometendo', 'também', 'os', 'planos', 'de', 'crescimento', 'do', 'Brasil'], ['A', 'confirmação', 'do', 'primeiro', 'caso', 'de', 'coronavírus', 'no', 'Brasil', 'um', 'homem', 'de', 'anos', 'que', 'contraiu', 'a', 'doença', 'em', 'uma', 'viagem', 'Itália', 'causou', 'preocupação', 'em', 'todo', 'o', 'País', 'e', 'o', 'Ministério', 'da', 'Saúde', 'precisou', 'colocar', 'em', 'prática', 'medidas', 'de', 'segurança', 'que', 'já', 'vinham', 'sendo', 'estudadas', 'desde', 'janeiro', 'quando', 'a', 'epidemia', 'surgiu', 'na', 'China', 'As', 'autoridades', 'sabiam', 'que', 'a', 'chegada', 'do', 'vírus', 'ao', 'Brasil', 'era', 'uma', 'questão', 'de', 'tempo', 'Outros', 'brasileiros', 'são', 'suspeitos', 'de', 'terem', 'pego', 'o', 'novo', 'vírus', 'dos', 'quais', 'também', 'passaram', 'pela', 'Itália', 'Em', 'estado', 'de', 'atenção', 'o', 'Brasil', 'já', 'pediu', 'Organização', 'Mundial', 'da', 'Saúde', 'OMS', 'que', 'declare', 'a', 'existência', 'de', 'uma', 'pandemia', 'quando', 'uma', 'doença', 'alastra', 'se', 'pelo', 'mundo'], ['O', 'brasileiro', 'infectado', 'pelo', 'novo', 'coronavírus', 'mora', 'em', 'São', 'Paulo', 'e', 'viajou', 'para', 'o', 'norte', 'da', 'Itália', 'entre', 'e', 'de', 'fevereiro', 'Para', 'voltar', 'ao', 'Brasil', 'o', 'idoso', 'embarcou', 'no', 'Aeroporto', 'Charles', 'de', 'Gaulle', 'em', 'Paris', 'no', 'dia', 'pela', 'Air', 'France', 'e', 'pousou', 'no', 'Aeroporto', 'de', 'Cumbica', 'em', 'Guarulhos', 'na', 'sexta', 'feira', 'Durante', 'a', 'viagem', 'ele', 'esteve', 'a', 'trabalho', 'nas', 'cidades', 'de', 'Verona', 'e', 'Turim', 'uma', 'das', 'regiões', 'mais', 'afetadas', 'pela', 'epidemia', 'na', 'Europa', 'Na', 'chegada', 'a', 'São', 'Paulo', 'ele', 'se', 'reuniu', 'com', 'cerca', 'de', 'parentes', 'na', 'casa', 'de', 'um', 'dos', 'filhos', 'no', 'domingo', 'para', 'uma', 'confraternização', 'no', 'Carnaval', 'Uma', 'neta', 'do', 'empresário', 'chegou', 'a', 'apresentar', 'sintomas', 'da', 'doença', 'mas', 'as', 'autoridades', 'sanitárias', 'apenas', 'acompanham', 'a', 'evolução', 'do', 'caso', 'e', 'não', 'confirmam', 'se', 'ela', 'está', 'contaminada', 'pelo', 'Covid', 'como', 'foi', 'denominado', 'o', 'novo', 'vírus', 'No', 'domingo', 'noite', 'ele', 'começou', 'a', 'sentir', 'os', 'sintomas', 'do', 'vírus', 'como', 'febre', 'tosse', 'seca', 'dor', 'de', 'garganta', 'e', 'coriza', 'Na', 'segunda', 'feira', 'o', 'homem', 'procurou', 'o', 'Hospital', 'Albert', 'Einstein', 'Os', 'médicos', 'fizeram', 'o', 'teste', 'confirmando', 'a', 'moléstia', 'Na', 'terça', 'feira', 'o', 'Instituto', 'Adolf', 'Lutz', 'fez', 'a', 'contraprova', 'e', 'não', 'restou', 'mais', 'dúvidas', 'era', 'o', 'primeiro', 'brasileiro', 'a', 'pegar', 'a', 'doença', 'que', 'abala', 'o', 'planeta', 'Entre', 'os', 'parentes', 'dois', 'adultos', 'e', 'uma', 'criança', 'são', 'de', 'Vinhedo', 'na', 'Grande', 'São', 'Paulo'], ['Agora', 'o', 'paciente', 'está', 'confinado', 'em', 'seu', 'apartamento', 'onde', 'deverá', 'ficar', 'em', 'quarentena', 'por', 'dias', 'Ele', 'está', 'acompanhado', 'apenas', 'pela', 'mulher', 'mas', 'em', 'ambientes', 'separados', 'Ela', 'não', 'apresentou', 'sintomas', 'até', 'agora', 'O', 'quadro', 'do', 'homem', 'infectado', 'está', 'evoluindo', 'muito', 'bem', 'disse', 'Alberto', 'Kanamura', 'secretário', 'executivo', 'da', 'Secretaria', 'Estadual', 'da', 'Saúde', 'O', 'empresário', 'está', 'sendo', 'orientado', 'a', 'não', 'compartilhar', 'talheres', 'com', 'os', 'demais', 'membros', 'da', 'família', 'e', 'de', 'ter', 'as', 'roupas', 'lavadas', 'e', 'o', 'lixo', 'descartado', 'separadamente', 'O', 'quadro', 'leve', 'e', 'não', 'inspira', 'maiores', 'cuidados', 'mas', 'se', 'houver', 'complicações', 'ele', 'pode', 'ser', 'hospitalizado'], ['Todos', 'os', 'seus', 'familiares', 'também', 'estão', 'sendo', 'monitorados', 'pela', 'vigilância', 'sanitária', 'bem', 'como', 'passageiros', 'que', 'voltaram', 'com', 'ele', 'no', 'avião', 'e', 'que', 'estiveram', 'nas', 'fileiras', 'frente', 'ao', 'lado', 'e', 'atrás', 'dele', 'Algumas', 'dessas', 'pessoas', 'já', 'foram', 'localizadas', 'e', 'procuraram', 'médicos', 'mas', 'nenhuma', 'delas', 'apresenta', 'sintomas', 'do', 'coronavírus', 'O', 'motorista', 'de', 'táxi', 'que', 'o', 'levou', 'do', 'Aeroporto', 'de', 'Cumbica', 'até', 'sua', 'residência', 'já', 'foi', 'contatado', 'mas', 'também', 'não', 'apresenta', 'sinais', 'da', 'infecção', 'Segundo', 'o', 'Ministério', 'da', 'Saúde', 'cada', 'infectado', 'em', 'média', 'transmite', 'a', 'doença', 'para', 'outras', 'três', 'pessoas', 'Os', 'exames', 'de', 'detecção', 'da', 'doença', 'são', 'feitos', 'a', 'partir', 'da', 'coleta', 'de', 'secreções', 'da', 'boca', 'e', 'nariz', 'Em', 'caso', 'de', 'confirmação', 'da', 'presença', 'do', 'vírus', 'a', 'contraprova', 'feita', 'por', 'quatro', 'grandes', 'laboratórios', 'de', 'referência', 'instalados', 'nas', 'principais', 'regiões', 'do', 'País'], ['Dólar', 'dispara'], ['A', 'notícia', 'da', 'chegada', 'do', 'vírus', 'ao', 'Brasil', 'acabou', 'provocando', 'pânico', 'As', 'pessoas', 'correram', 'para', 'as', 'farmácias', 'em', 'busca', 'de', 'máscaras', 'cirúrgicas', 'e', 'lcool', 'gel', 'esgotando', 'os', 'produtos', 'nas', 'gôndolas', 'No', 'mercado', 'financeiro', 'a', 'reação', 'foi', 'imediata', 'A', 'bolsa', 'despencou', 'só', 'na', 'ltima', 'quarta', 'feira', 'um', 'dia', 'depois', 'do', 'anúncio', 'da', 'entrada', 'do', 'Covid', 'ao', 'País', 'O', 'dólar', 'voltou', 'a', 'disparar', 'chegando', 'a', 'R', 'na', 'quinta', 'feira', 'atingindo', 'o', 'maior', 'valor', 'nominal', 'de', 'fechamento', 'já', 'registrado', 'Na', 'indústria', 'a', 'dificuldade', 'para', 'conseguir', 'peças', 'vindas', 'da', 'China', 'começa', 'a', 'paralisar', 'linhas', 'de', 'produção', 'O', 'vírus', 'ameaça', 'inclusive', 'as', 'perspectivas', 'de', 'crescimento', 'da', 'economia', 'brasileira', 'Ao', 'invés', 'de', 'um', 'aumento', 'de', 'do', 'PIB', 'fala', 'se', 'agora', 'numa', 'alta', 'de', 'no', 'máximo'], ['Fonte', 'https', 'istoe', 'com', 'br', 'coronavirus', 'chega', 'ao', 'brasil']]\n",
            "[['coronavírus', 'chega', 'ao', 'brasil'], ['anna', 'frança', 'h30'], ['com', 'a', 'primeira', 'vítima', 'confirmada', 'e', 'uma', 'série', 'de', 'novos', 'suspeitos', 'de', 'contaminação', 'pela', 'epidemia', 'o', 'brasil', 'começa', 'a', 'enfrentar', 'seu', 'grande', 'teste', 'sanitário', 'e', 'de', 'esclarecimento', 'população', 'o', 'drama', 'que', 'essa', 'praga', 'se', 'alastra', 'inclusive', 'pelos', 'mercados', 'criando', 'pânico', 'e', 'comprometendo', 'também', 'os', 'planos', 'de', 'crescimento', 'do', 'brasil'], ['a', 'confirmação', 'do', 'primeiro', 'caso', 'de', 'coronavírus', 'no', 'brasil', 'um', 'homem', 'de', 'anos', 'que', 'contraiu', 'a', 'doença', 'em', 'uma', 'viagem', 'itália', 'causou', 'preocupação', 'em', 'todo', 'o', 'país', 'e', 'o', 'ministério', 'da', 'saúde', 'precisou', 'colocar', 'em', 'prática', 'medidas', 'de', 'segurança', 'que', 'já', 'vinham', 'sendo', 'estudadas', 'desde', 'janeiro', 'quando', 'a', 'epidemia', 'surgiu', 'na', 'china', 'as', 'autoridades', 'sabiam', 'que', 'a', 'chegada', 'do', 'vírus', 'ao', 'brasil', 'era', 'uma', 'questão', 'de', 'tempo', 'outros', 'brasileiros', 'são', 'suspeitos', 'de', 'terem', 'pego', 'o', 'novo', 'vírus', 'dos', 'quais', 'também', 'passaram', 'pela', 'itália', 'em', 'estado', 'de', 'atenção', 'o', 'brasil', 'já', 'pediu', 'organização', 'mundial', 'da', 'saúde', 'oms', 'que', 'declare', 'a', 'existência', 'de', 'uma', 'pandemia', 'quando', 'uma', 'doença', 'alastra', 'se', 'pelo', 'mundo'], ['o', 'brasileiro', 'infectado', 'pelo', 'novo', 'coronavírus', 'mora', 'em', 'são', 'paulo', 'e', 'viajou', 'para', 'o', 'norte', 'da', 'itália', 'entre', 'e', 'de', 'fevereiro', 'para', 'voltar', 'ao', 'brasil', 'o', 'idoso', 'embarcou', 'no', 'aeroporto', 'charles', 'de', 'gaulle', 'em', 'paris', 'no', 'dia', 'pela', 'air', 'france', 'e', 'pousou', 'no', 'aeroporto', 'de', 'cumbica', 'em', 'guarulhos', 'na', 'sexta', 'feira', 'durante', 'a', 'viagem', 'ele', 'esteve', 'a', 'trabalho', 'nas', 'cidades', 'de', 'verona', 'e', 'turim', 'uma', 'das', 'regiões', 'mais', 'afetadas', 'pela', 'epidemia', 'na', 'europa', 'na', 'chegada', 'a', 'são', 'paulo', 'ele', 'se', 'reuniu', 'com', 'cerca', 'de', 'parentes', 'na', 'casa', 'de', 'um', 'dos', 'filhos', 'no', 'domingo', 'para', 'uma', 'confraternização', 'no', 'carnaval', 'uma', 'neta', 'do', 'empresário', 'chegou', 'a', 'apresentar', 'sintomas', 'da', 'doença', 'mas', 'as', 'autoridades', 'sanitárias', 'apenas', 'acompanham', 'a', 'evolução', 'do', 'caso', 'e', 'não', 'confirmam', 'se', 'ela', 'está', 'contaminada', 'pelo', 'covid', 'como', 'foi', 'denominado', 'o', 'novo', 'vírus', 'no', 'domingo', 'noite', 'ele', 'começou', 'a', 'sentir', 'os', 'sintomas', 'do', 'vírus', 'como', 'febre', 'tosse', 'seca', 'dor', 'de', 'garganta', 'e', 'coriza', 'na', 'segunda', 'feira', 'o', 'homem', 'procurou', 'o', 'hospital', 'albert', 'einstein', 'os', 'médicos', 'fizeram', 'o', 'teste', 'confirmando', 'a', 'moléstia', 'na', 'terça', 'feira', 'o', 'instituto', 'adolf', 'lutz', 'fez', 'a', 'contraprova', 'e', 'não', 'restou', 'mais', 'dúvidas', 'era', 'o', 'primeiro', 'brasileiro', 'a', 'pegar', 'a', 'doença', 'que', 'abala', 'o', 'planeta', 'entre', 'os', 'parentes', 'dois', 'adultos', 'e', 'uma', 'criança', 'são', 'de', 'vinhedo', 'na', 'grande', 'são', 'paulo'], ['agora', 'o', 'paciente', 'está', 'confinado', 'em', 'seu', 'apartamento', 'onde', 'deverá', 'ficar', 'em', 'quarentena', 'por', 'dias', 'ele', 'está', 'acompanhado', 'apenas', 'pela', 'mulher', 'mas', 'em', 'ambientes', 'separados', 'ela', 'não', 'apresentou', 'sintomas', 'até', 'agora', 'o', 'quadro', 'do', 'homem', 'infectado', 'está', 'evoluindo', 'muito', 'bem', 'disse', 'alberto', 'kanamura', 'secretário', 'executivo', 'da', 'secretaria', 'estadual', 'da', 'saúde', 'o', 'empresário', 'está', 'sendo', 'orientado', 'a', 'não', 'compartilhar', 'talheres', 'com', 'os', 'demais', 'membros', 'da', 'família', 'e', 'de', 'ter', 'as', 'roupas', 'lavadas', 'e', 'o', 'lixo', 'descartado', 'separadamente', 'o', 'quadro', 'leve', 'e', 'não', 'inspira', 'maiores', 'cuidados', 'mas', 'se', 'houver', 'complicações', 'ele', 'pode', 'ser', 'hospitalizado'], ['todos', 'os', 'seus', 'familiares', 'também', 'estão', 'sendo', 'monitorados', 'pela', 'vigilância', 'sanitária', 'bem', 'como', 'passageiros', 'que', 'voltaram', 'com', 'ele', 'no', 'avião', 'e', 'que', 'estiveram', 'nas', 'fileiras', 'frente', 'ao', 'lado', 'e', 'atrás', 'dele', 'algumas', 'dessas', 'pessoas', 'já', 'foram', 'localizadas', 'e', 'procuraram', 'médicos', 'mas', 'nenhuma', 'delas', 'apresenta', 'sintomas', 'do', 'coronavírus', 'o', 'motorista', 'de', 'táxi', 'que', 'o', 'levou', 'do', 'aeroporto', 'de', 'cumbica', 'até', 'sua', 'residência', 'já', 'foi', 'contatado', 'mas', 'também', 'não', 'apresenta', 'sinais', 'da', 'infecção', 'segundo', 'o', 'ministério', 'da', 'saúde', 'cada', 'infectado', 'em', 'média', 'transmite', 'a', 'doença', 'para', 'outras', 'três', 'pessoas', 'os', 'exames', 'de', 'detecção', 'da', 'doença', 'são', 'feitos', 'a', 'partir', 'da', 'coleta', 'de', 'secreções', 'da', 'boca', 'e', 'nariz', 'em', 'caso', 'de', 'confirmação', 'da', 'presença', 'do', 'vírus', 'a', 'contraprova', 'feita', 'por', 'quatro', 'grandes', 'laboratórios', 'de', 'referência', 'instalados', 'nas', 'principais', 'regiões', 'do', 'país'], ['dólar', 'dispara'], ['a', 'notícia', 'da', 'chegada', 'do', 'vírus', 'ao', 'brasil', 'acabou', 'provocando', 'pânico', 'as', 'pessoas', 'correram', 'para', 'as', 'farmácias', 'em', 'busca', 'de', 'máscaras', 'cirúrgicas', 'e', 'lcool', 'gel', 'esgotando', 'os', 'produtos', 'nas', 'gôndolas', 'no', 'mercado', 'financeiro', 'a', 'reação', 'foi', 'imediata', 'a', 'bolsa', 'despencou', 'só', 'na', 'ltima', 'quarta', 'feira', 'um', 'dia', 'depois', 'do', 'anúncio', 'da', 'entrada', 'do', 'covid', 'ao', 'país', 'o', 'dólar', 'voltou', 'a', 'disparar', 'chegando', 'a', 'r', 'na', 'quinta', 'feira', 'atingindo', 'o', 'maior', 'valor', 'nominal', 'de', 'fechamento', 'já', 'registrado', 'na', 'indústria', 'a', 'dificuldade', 'para', 'conseguir', 'peças', 'vindas', 'da', 'china', 'começa', 'a', 'paralisar', 'linhas', 'de', 'produção', 'o', 'vírus', 'ameaça', 'inclusive', 'as', 'perspectivas', 'de', 'crescimento', 'da', 'economia', 'brasileira', 'ao', 'invés', 'de', 'um', 'aumento', 'de', 'do', 'pib', 'fala', 'se', 'agora', 'numa', 'alta', 'de', 'no', 'máximo'], ['fonte', 'https', 'istoe', 'com', 'br', 'coronavirus', 'chega', 'ao', 'brasil']]\n",
            "['coronavírus', 'chega', 'brasil', 'anna', 'frança', 'h30', 'primeira', 'vítima', 'confirmada', 'série', 'novos', 'suspeitos', 'contaminação', 'epidemia', 'brasil', 'começa', 'enfrentar', 'grande', 'teste', 'sanitário', 'esclarecimento', 'população', 'drama', 'praga', 'alastra', 'inclusive', 'mercados', 'criando', 'pânico', 'comprometendo', 'planos', 'crescimento', 'brasil', 'confirmação', 'primeiro', 'caso', 'coronavírus', 'brasil', 'homem', 'anos', 'contraiu', 'doença', 'viagem', 'itália', 'causou', 'preocupação', 'todo', 'país', 'ministério', 'saúde', 'precisou', 'colocar', 'prática', 'medidas', 'segurança', 'vinham', 'sendo', 'estudadas', 'desde', 'janeiro', 'epidemia', 'surgiu', 'china', 'autoridades', 'sabiam', 'chegada', 'vírus', 'brasil', 'questão', 'tempo', 'outros', 'brasileiros', 'suspeitos', 'terem', 'pego', 'novo', 'vírus', 'quais', 'passaram', 'itália', 'estado', 'atenção', 'brasil', 'pediu', 'organização', 'mundial', 'saúde', 'oms', 'declare', 'existência', 'pandemia', 'doença', 'alastra', 'mundo', 'brasileiro', 'infectado', 'novo', 'coronavírus', 'mora', 'paulo', 'viajou', 'norte', 'itália', 'fevereiro', 'voltar', 'brasil', 'idoso', 'embarcou', 'aeroporto', 'charles', 'gaulle', 'paris', 'dia', 'air', 'france', 'pousou', 'aeroporto', 'cumbica', 'guarulhos', 'sexta', 'feira', 'durante', 'viagem', 'trabalho', 'cidades', 'verona', 'turim', 'regiões', 'afetadas', 'epidemia', 'europa', 'chegada', 'paulo', 'reuniu', 'cerca', 'parentes', 'casa', 'filhos', 'domingo', 'confraternização', 'carnaval', 'neta', 'empresário', 'chegou', 'apresentar', 'sintomas', 'doença', 'autoridades', 'sanitárias', 'apenas', 'acompanham', 'evolução', 'caso', 'confirmam', 'contaminada', 'covid', 'denominado', 'novo', 'vírus', 'domingo', 'noite', 'começou', 'sentir', 'sintomas', 'vírus', 'febre', 'tosse', 'seca', 'dor', 'garganta', 'coriza', 'segunda', 'feira', 'homem', 'procurou', 'hospital', 'albert', 'einstein', 'médicos', 'fizeram', 'teste', 'confirmando', 'moléstia', 'terça', 'feira', 'instituto', 'adolf', 'lutz', 'fez', 'contraprova', 'restou', 'dúvidas', 'primeiro', 'brasileiro', 'pegar', 'doença', 'abala', 'planeta', 'parentes', 'dois', 'adultos', 'criança', 'vinhedo', 'grande', 'paulo', 'agora', 'paciente', 'confinado', 'apartamento', 'onde', 'deverá', 'ficar', 'quarentena', 'dias', 'acompanhado', 'apenas', 'mulher', 'ambientes', 'separados', 'apresentou', 'sintomas', 'agora', 'quadro', 'homem', 'infectado', 'evoluindo', 'bem', 'disse', 'alberto', 'kanamura', 'secretário', 'executivo', 'secretaria', 'estadual', 'saúde', 'empresário', 'sendo', 'orientado', 'compartilhar', 'talheres', 'demais', 'membros', 'família', 'ter', 'roupas', 'lavadas', 'lixo', 'descartado', 'separadamente', 'quadro', 'leve', 'inspira', 'maiores', 'cuidados', 'complicações', 'pode', 'ser', 'hospitalizado', 'todos', 'familiares', 'sendo', 'monitorados', 'vigilância', 'sanitária', 'bem', 'passageiros', 'voltaram', 'avião', 'fileiras', 'frente', 'lado', 'atrás', 'algumas', 'dessas', 'pessoas', 'localizadas', 'procuraram', 'médicos', 'nenhuma', 'apresenta', 'sintomas', 'coronavírus', 'motorista', 'táxi', 'levou', 'aeroporto', 'cumbica', 'residência', 'contatado', 'apresenta', 'sinais', 'infecção', 'segundo', 'ministério', 'saúde', 'cada', 'infectado', 'média', 'transmite', 'doença', 'outras', 'três', 'pessoas', 'exames', 'detecção', 'doença', 'feitos', 'partir', 'coleta', 'secreções', 'boca', 'nariz', 'caso', 'confirmação', 'presença', 'vírus', 'contraprova', 'feita', 'quatro', 'grandes', 'laboratórios', 'referência', 'instalados', 'principais', 'regiões', 'país', 'dólar', 'dispara', 'notícia', 'chegada', 'vírus', 'brasil', 'acabou', 'provocando', 'pânico', 'pessoas', 'correram', 'farmácias', 'busca', 'máscaras', 'cirúrgicas', 'lcool', 'gel', 'esgotando', 'produtos', 'gôndolas', 'mercado', 'financeiro', 'reação', 'imediata', 'bolsa', 'despencou', 'ltima', 'quarta', 'feira', 'dia', 'anúncio', 'entrada', 'covid', 'país', 'dólar', 'voltou', 'disparar', 'chegando', 'r', 'quinta', 'feira', 'atingindo', 'maior', 'valor', 'nominal', 'fechamento', 'registrado', 'indústria', 'dificuldade', 'conseguir', 'peças', 'vindas', 'china', 'começa', 'paralisar', 'linhas', 'produção', 'vírus', 'ameaça', 'inclusive', 'perspectivas', 'crescimento', 'economia', 'brasileira', 'invés', 'aumento', 'pib', 'fala', 'agora', 'alta', 'máximo', 'fonte', 'https', 'istoe', 'br', 'coronavirus', 'chega', 'brasil']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frequência dos Termos"
      ],
      "metadata": {
        "id": "-TGhJG721ekh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frequencia = nltk.FreqDist(tokens_sem_stopwords)\n",
        "frequencia.most_common(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnUdCZnO1ezX",
        "outputId": "61546fa2-b98a-4fff-8ac2-d4661147cb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('brasil', 9),\n",
              " ('vírus', 7),\n",
              " ('doença', 6),\n",
              " ('feira', 5),\n",
              " ('coronavírus', 4),\n",
              " ('saúde', 4),\n",
              " ('sintomas', 4),\n",
              " ('epidemia', 3),\n",
              " ('caso', 3),\n",
              " ('homem', 3),\n",
              " ('itália', 3),\n",
              " ('país', 3),\n",
              " ('sendo', 3),\n",
              " ('chegada', 3),\n",
              " ('novo', 3),\n",
              " ('infectado', 3),\n",
              " ('paulo', 3),\n",
              " ('aeroporto', 3),\n",
              " ('agora', 3),\n",
              " ('pessoas', 3),\n",
              " ('chega', 2),\n",
              " ('suspeitos', 2),\n",
              " ('começa', 2),\n",
              " ('grande', 2),\n",
              " ('teste', 2),\n",
              " ('alastra', 2),\n",
              " ('inclusive', 2),\n",
              " ('pânico', 2),\n",
              " ('crescimento', 2),\n",
              " ('confirmação', 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extração de Palavras Chaves com Tf-idf\n",
        "\n"
      ],
      "metadata": {
        "id": "29hv6ACo3Jhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf_idf_vec = TfidfVectorizer(use_idf=True)\n",
        "tf_idf_vec.fit(tokens_sem_stopwords)\n",
        "\n",
        "tf_idf_vec.transform(tokens_sem_stopwords)\n",
        "\n",
        "matriz = tf_idf_vec.fit_transform(tokens_sem_stopwords).toarray()\n",
        "\n",
        "features_name = tf_idf_vec.get_feature_names()\n",
        "\n",
        "print(features_name)\n",
        "\n",
        "print(matriz)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(matriz)):\n",
        "  for j in range(len(matriz[i])):\n",
        "    if matriz[i][j] != 0:\n",
        "      print(matriz[i][j])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gSLoAdXS_kHN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}